{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpflow\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_history as gh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feather\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_cols(params, indices, name=None):\n",
    "    \"\"\"Gather columns of a 2D tensor.\n",
    "\n",
    "    Args:\n",
    "        params: A 2D tensor.\n",
    "        indices: A 1D tensor. Must be one of the following types: ``int32``, ``int64``.\n",
    "        name: A name for the operation (optional).\n",
    "\n",
    "    Returns:\n",
    "        A 2D Tensor. Has the same type as ``params``.\n",
    "    \"\"\"\n",
    "    with tf.op_scope([params, indices], name, \"gather_cols\") as scope:\n",
    "        # Check input\n",
    "        params = tf.convert_to_tensor(params, name=\"params\")\n",
    "        indices = tf.convert_to_tensor(indices, name=\"indices\")\n",
    "        try:\n",
    "            params.get_shape().assert_has_rank(2)\n",
    "        except ValueError:\n",
    "            raise ValueError('\\'params\\' must be 2D.')\n",
    "        try:\n",
    "            indices.get_shape().assert_has_rank(1)\n",
    "        except ValueError:\n",
    "            raise ValueError('\\'params\\' must be 1D.')\n",
    "\n",
    "        # Define op\n",
    "        p_shape = tf.shape(params)\n",
    "        p_flat = tf.reshape(params, [-1])\n",
    "        i_flat = tf.reshape(tf.reshape(tf.range(0, p_shape[0]) * p_shape[1],\n",
    "                                       [-1, 1]) + indices, [-1])\n",
    "        return tf.reshape(tf.gather(p_flat, i_flat),\n",
    "                          [p_shape[0], -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 1.1, 0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 1.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 1.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 1.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1, 0.1, 1.1]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(6)+.1*np.ones((6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>prior</th>\n",
       "      <th>transform</th>\n",
       "      <th>trainable</th>\n",
       "      <th>shape</th>\n",
       "      <th>fixed_shape</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Parameter</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>[[1.0, 0.0], [1.0, 0.0]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<gpflow.params.parameter.Parameter at 0x108ad9cc0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpflow.Param([[1.0,0],[1,0]], transform=gpflow.transforms.positive,dtype=gpflow.settings.float_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr = 10*np.eye(100)\n",
    "gr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class CustomKernel(gpflow.kernels.Kernel):\n",
    "    def __init__(self,input_dim, mysession=None,rhos=None,select_users=None,\n",
    "                 active_dims=None, ARD=None, name=None):\n",
    "        super().__init__(input_dim)\n",
    "\n",
    "        self.sigma_u = gpflow.Param([[1.0,0.1],[0.1,1.0]], transform=gpflow.transforms.positive,\n",
    "                                    dtype=gpflow.settings.float_type)\n",
    "        \n",
    "        #tf.constant(np.array([[1.0,0.1],[0.1,1.0]]))\n",
    "        \n",
    "        self.sigma_theta = gpflow.Param(np.array([[1.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
    "       [0.1, 1.1, 0.1, 0.1, 0.1, 0.1],\n",
    "       [0.1, 0.1, 1.1, 0.1, 0.1, 0.1],\n",
    "       [0.1, 0.1, 0.1, 1.1, 0.1, 0.1],\n",
    "       [0.1, 0.1, 0.1, 0.1, 1.1, 0.1],\n",
    "       [0.1, 0.1, 0.1, 0.1, 0.1, 1.1]]), transform=gpflow.transforms.positive,\n",
    "                                    dtype=gpflow.settings.float_type)\n",
    "        #print(self.sigma_theta)\n",
    "        #gpflow.Param(1.0, transform=gpflow.transforms.positive,\n",
    "                                  #dtype=gpflow.settings.float_type)\n",
    "        \n",
    "        self.sigma_v =  gpflow.Param(np.array([[10.0,0.0],[0.0,10.0]]), transform=gpflow.transforms.positive,\n",
    "                                    dtype=gpflow.settings.float_type)\n",
    "        #gpflow.Param(1.0, transform=gpflow.transforms.positive,\n",
    "                                  #dtype=gpflow.settings.float_type)\n",
    "        self.mysession=mysession\n",
    "        \n",
    "        self.rhos = tf.constant(rhos)\n",
    "        self.select_users = tf.constant(select_users)\n",
    "        ##will it freak out if there is no parameter?\n",
    "        \n",
    "    \n",
    "    @gpflow.params_as_tensors\n",
    "    def rbf_custom(self, X, X2=None):\n",
    "        #print(X)\n",
    "        #print(X2)\n",
    "        if X2 is None:\n",
    "             X2=X\n",
    "        return tf.exp(-tf.divide(tf.square(tf.subtract(X,X2)),tf.constant(1.0,dtype=tf.float64)))\n",
    "        return tf.constant(1.0,dtype=tf.float64)\n",
    "    #tf.exp(-tf.subtract(X,X2) / float(2.2))\n",
    "    \n",
    "    @gpflow.params_as_tensors\n",
    "    def get_all_sigmas(self,sigma_v,g_one,g_two,day_one,day_two):\n",
    "    #sigmax = [[] for i in range(100)]\n",
    "    #tf.placeholder(tf.float64, shape=(100, 2,2))\n",
    "    \n",
    "            \n",
    "        #print('eff')\n",
    "        #print(effects.shape)\n",
    "        #user_term = tf.constant(np.array([[0.0,0.0],[0.0,0.0]]))           \n",
    "        \n",
    "\n",
    "\n",
    "        #print('eff')\n",
    "        #print(effects.shape)\n",
    "        #effects = tf.tensordot(effects,tf.transpose(g_two),axes = [[1],[0]])\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        get_g = g_one\n",
    "        get_g_two = g_two\n",
    "        to_return = [[] for i in range(100)]\n",
    "        for i in range(100):\n",
    "            temp = [[] for i in range(100)]\n",
    "            for j in range( 100):\n",
    "                rho = self.rbf_custom(day_one[i], X2=day_two[j])\n",
    "            #print(sess.run(rho))\n",
    "                val = rho[0]\n",
    "        #tf.scalar_mul(val,sigma_v)\n",
    "            #print(val)\n",
    "                this_sigma = tf.scalar_mul(val,sigma_v)\n",
    "            #print(this_sigma)\n",
    "                effects = tf.tensordot(get_g[i],this_sigma,axes=[[0],[1]])\n",
    "                effects = tf.tensordot(effects,get_g_two[j],axes = [[0],[0]])\n",
    "                temp[j]=effects\n",
    "            to_return[i]=temp\n",
    "        \n",
    "        return to_return\n",
    "    \n",
    "    @gpflow.params_as_tensors\n",
    "    def K(self, X, X2=None):\n",
    " \n",
    "\n",
    "      \n",
    "        \n",
    "        f_one = gather_cols(X, [0,1,2,3,4,5], name=None)\n",
    "        g_one = gather_cols(X, [6,7], name=None)\n",
    "        user_id_one = gather_cols(X, [8], name=None)\n",
    "        day_one = gather_cols(X, [9], name=None)\n",
    "\n",
    "\n",
    "\n",
    "        #print(f_one.get_shape())\n",
    "        \n",
    "        if not X2 is None:\n",
    "            print('called')\n",
    "            f_two = gather_cols(X2, [0,1,2,3,4,5], name=None)\n",
    "            g_two = gather_cols(X2, [6,7], name=None)  \n",
    "            user_id_two = gather_cols(X2, [8], name=None)\n",
    "            day_two = gather_cols(X2, [9], name=None)\n",
    "            \n",
    "         \n",
    "            \n",
    "        else:\n",
    "            #print('called')\n",
    "            user_id_two = X[-2]\n",
    "            day_two = day_one\n",
    "            f_two = f_one\n",
    "            g_two=g_one\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        #rho_term = self.rbf_custom(day_one,X2=day_two)\n",
    "        #print('rho')\n",
    "        #print(rho_term.get_shape())\n",
    "        \n",
    "        baselines = tf.tensordot(tf.transpose(f_one),self.sigma_theta,axes=[[0],[1]])\n",
    "        #print('baselines')\n",
    "        #print(baselines.get_shape())\n",
    "        baselines = tf.tensordot(baselines,tf.transpose(f_two),axes=[[1],[0]])\n",
    "        \n",
    "        \n",
    "        #rhos = tf.constant(np.array([[self.rbf_custom(day_one[i], X2=day_two[j])[0]] \\\n",
    "                                     #for i, j in zip([i for i in range(100)], [j for j in range(100)])]))\n",
    "        \n",
    "        \n",
    "        #effects = self.get_all_sigmas(self.sigma_v,g_one,g_two,day_one,day_two)\n",
    "            #print('look at shape')t\n",
    "            #print(baselines)\n",
    "        #print('baselines')\n",
    "        #print(baselines.get_shape())\n",
    "        \n",
    "        #effect_term = tf.tensordot(rho_term,self.sigma_v,axes=[[0],[0]])\n",
    "\n",
    "        #user_term = tf.constant(np.array([[0.0,0.0],[0.0,0.0]]))           \n",
    "        #effect_term = tf.add(user_term,effect_term)\n",
    "       #print('eff')\n",
    "        #print(effect_term.shape)\n",
    "        \n",
    "        #print('eff')\n",
    "        #print(effects.shape)\n",
    "        #user_term = tf.constant(np.array([[0.0,0.0],[0.0,0.0]]))           \n",
    "        \n",
    "\n",
    "\n",
    "        #print('eff')\n",
    "        #print(effects.shape)\n",
    "        \n",
    "        ##important\n",
    "        effects = tf.tensordot(tf.transpose(g_one),self.sigma_u,axes=[[0],[1]])\n",
    "       \n",
    "        \n",
    "        effects = tf.tensordot(effects,tf.transpose(g_two),axes = [[1],[0]])\n",
    "        effects_one = tf.multiply(effects,self.select_users)\n",
    "        \n",
    "        \n",
    "        \n",
    "        effects = tf.tensordot(tf.transpose(g_one),self.sigma_v,axes=[[0],[1]])\n",
    "       \n",
    "        \n",
    "        effects = tf.tensordot(effects,tf.transpose(g_two),axes = [[1],[0]])\n",
    "        effects_two = tf.multiply(effects,self.rhos)\n",
    "        \n",
    "        effects = tf.add(effects_one,effects_two)\n",
    "   \n",
    "        \n",
    "        #print('eff')\n",
    "        #print(effects.shape)\n",
    "        result = tf.add(baselines,effects)\n",
    "        \n",
    "        noise = 1000*np.eye(100)\n",
    "        result = tf.add(result,tf.constant(noise))\n",
    "        #effect_term = tf.add(user_term,effect_term)\n",
    "        print('r')\n",
    "        print(result.shape)\n",
    "        \n",
    "        \n",
    "        return result\n",
    "       \n",
    "        \n",
    "        #self.variance * tf.minimum(X, tf.transpose(X2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "##need to reformat history\n",
    "def put_x_together(h):\n",
    "    X = []\n",
    "    \n",
    "    for i in range(len(h.states)):\n",
    "        state_vector = h.states[i]\n",
    "        state_vector.append(float(h.users[i]))\n",
    "        state_vector.append(float(h.day_function[i]))\n",
    "        X.append(state_vector)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = gh.get_history(8,100,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = put_x_together(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'users' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ecac3025b76d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0musers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'users' is not defined"
     ]
    }
   ],
   "source": [
    "users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = np.array([[float(X[i][8]==X[j][8]) for j in range(100)] for i in range(100)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_custom_np( X, X2=None):\n",
    "        #print(X)\n",
    "        #print(X2)\n",
    "        if X2 is None:\n",
    "             X2=X\n",
    "        return math.exp(-((X-X2)**2)/1.0)\n",
    "        #tf.divide(tf.square(-tf.subtract(X,X2)),tf.constant(1.0,dtype=tf.float64)))\n",
    "rdayone = [x[9] for x in X]\n",
    "rdaytwo = rdayone\n",
    "rhos = np.array([[rbf_custom_np( rdayone[i], X2=rdaytwo[j]) for j in range(100)] for i in range(100)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([[float(r)] for r in history.rewards])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r\n",
      "(100, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "k =  CustomKernel(7,mysession=sess,rhos=rhos,select_users=users)\n",
    "m = gpflow.models.GPR(X,y, kern=k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 542.208214\n",
      "  Number of iterations: 29\n",
      "  Number of functions evaluations: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 542.208214\n",
      "  Number of iterations: 29\n",
      "  Number of functions evaluations: 33\n"
     ]
    }
   ],
   "source": [
    "gpflow.train.ScipyOptimizer().minimize(m,session=sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r\n",
      "(100, 100)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "term= m.kern.K(X,X2=X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "trm = term.eval(session=sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e-06, 1.00000000e-06, 1.00000000e-06, 1.00000000e-06,\n",
       "        1.00000000e-06, 1.00000000e-06],\n",
       "       [1.00000000e-06, 2.82181269e+04, 3.93356460e+04, 3.17277287e+04,\n",
       "        1.12994714e+04, 1.54360619e+04],\n",
       "       [1.00000000e-06, 3.93356460e+04, 3.09361077e+04, 3.81722019e+04,\n",
       "        7.61246282e+03, 1.69021882e+04],\n",
       "       [1.00000000e-06, 3.17277287e+04, 3.81722019e+04, 1.90154340e+04,\n",
       "        1.27744193e+04, 1.33486549e+04],\n",
       "       [1.00000000e-06, 1.12994714e+04, 7.61246282e+03, 1.27744193e+04,\n",
       "        1.00000000e-06, 4.90371038e+03],\n",
       "       [1.00000000e-06, 1.54360619e+04, 1.69021882e+04, 1.33486549e+04,\n",
       "        4.90371038e+03, 1.00000000e-06]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.kern.sigma_theta.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>prior</th>\n",
       "      <th>transform</th>\n",
       "      <th>trainable</th>\n",
       "      <th>shape</th>\n",
       "      <th>fixed_shape</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GPR/kern/sigma_theta</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>(6, 6)</td>\n",
       "      <td>True</td>\n",
       "      <td>[[1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPR/kern/sigma_u</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>[[1e-06, 1e-06], [1e-06, 1e-06]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPR/kern/sigma_v</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>[[1e-06, 1.0000000002220446e-06], [1.000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPR/likelihood/variance</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>None</td>\n",
       "      <td>+ve</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>True</td>\n",
       "      <td>1803.5640939878183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             class prior transform  trainable   shape  \\\n",
       "GPR/kern/sigma_theta     Parameter  None       +ve       True  (6, 6)   \n",
       "GPR/kern/sigma_u         Parameter  None       +ve       True  (2, 2)   \n",
       "GPR/kern/sigma_v         Parameter  None       +ve       True  (2, 2)   \n",
       "GPR/likelihood/variance  Parameter  None       +ve       True      ()   \n",
       "\n",
       "                         fixed_shape  \\\n",
       "GPR/kern/sigma_theta            True   \n",
       "GPR/kern/sigma_u                True   \n",
       "GPR/kern/sigma_v                True   \n",
       "GPR/likelihood/variance         True   \n",
       "\n",
       "                                                                     value  \n",
       "GPR/kern/sigma_theta     [[1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06], [...  \n",
       "GPR/kern/sigma_u                          [[1e-06, 1e-06], [1e-06, 1e-06]]  \n",
       "GPR/kern/sigma_v         [[1e-06, 1.0000000002220446e-06], [1.000000000...  \n",
       "GPR/likelihood/variance                                 1803.5640939878183  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.as_pandas_table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_kernel_and_sigma_u(all_xs,all_ys):\n",
    "    k =  CustomKernel(all_xs.shape[1])\n",
    "    m = gpflow.models.GPR(all_xs, all_ys, kern=k)\n",
    "    gpflow.train.ScipyOptimizer().minimize(m,session=sess)\n",
    "    #sigma_u = m.kern.sigma_u\n",
    "    #.value\n",
    "    cov = np.zeros((all_xs.shape[0],all_xs.shape[0]))\n",
    "    term = m.kern.K(all_xs,X2=all_xs)\n",
    "    print(m.as_pandas_table())\n",
    "    #for i in range(all_xs.shape[0]):\n",
    "        #for j in range(all_xs.shape[0]):\n",
    "            #print(type(all_xs[i][0]))\n",
    "           # term = m.kern.K(all_xs[i],all_xs[j])\n",
    "            #term = tf.cast(term, tf.float32)\n",
    "           # cov[i][j]=term\n",
    "            #term.eval(session=sess)\n",
    "            #term.eval(session=sess)\n",
    "    return term.eval(session=sess)\n",
    "#,sigma_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n",
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n",
      "WARNING:gpflow.logdensities:Shape of mu may be unknown or not 2D.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?)\n",
      "Tensor(\"GPR-e94f3f47-854/likelihood_1/strided_slice_1:0\", dtype=float64)\n",
      "Tensor(\"GPR-e94f3f47-854/likelihood_1/strided_slice_4:0\", dtype=float64)\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 542.233190\n",
      "  Number of iterations: 32\n",
      "  Number of functions evaluations: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 542.233190\n",
      "  Number of iterations: 32\n",
      "  Number of functions evaluations: 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n",
      "called\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17.62061977 16.3121152  16.83757731 15.21358701 18.68006498  3.\n",
      " 15.        ]\n",
      "[17.62061977 16.3121152  16.83757731 15.21358701 18.68006498  3.\n",
      " 15.        ]\n",
      "                             class prior transform  trainable shape  \\\n",
      "GPR/likelihood/variance  Parameter  None       +ve       True    ()   \n",
      "\n",
      "                         fixed_shape               value  \n",
      "GPR/likelihood/variance         True  2684.0070684618827  \n"
     ]
    }
   ],
   "source": [
    "cov = obtain_kernel_and_sigma_u(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RT(y,X,sigma_theta):\n",
    "    \n",
    "    to_return = [y[i]-np.dot(X[i][0:6],np.ones(6)) for i in range(len(X))]\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_adjusted = get_RT(y,X,sigma_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_H():\n",
    "    return np.transpose(np.array([[1,0,0,0,0,0],[0,0,1,0,1,0]]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MT(new_x,sigma_theta,sigma_u,sigma_v,history,H):\n",
    "    \n",
    "    psi = new_x[6:8]\n",
    "    user_id = new_x[8]\n",
    "    day_id = new_x[9]\n",
    "    \n",
    "    to_return = [[] for i in range(history.shape[0])]\n",
    "    \n",
    "    for x_old_i in range(len(history)):\n",
    "        x_old = history[x_old_i]\n",
    "        phi = x_old[:6]\n",
    "       \n",
    "        old_user_id = x_old[8]\n",
    "        old_day_id = x_old[9]\n",
    "        \n",
    "        inner = float(old_user_id==user_id)*sigma_u+rbf_custom_np(day_id,old_day_id)*sigma_v\n",
    "        #print(inner.shape)\n",
    "        #print(H.shape)\n",
    "        inner = np.dot(H,inner)\n",
    "        #print(inner.shape)\n",
    "        inner = np.dot(inner,np.transpose(H))\n",
    "        #print(inner.shape)\n",
    "        inner = np.add(sigma_theta,inner)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        term = np.dot(np.transpose(phi),inner)\n",
    "        to_return[x_old_i]=[i for i in term]\n",
    "    return to_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "    sigma_theta = np.array([[1.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
    "       [0.1, 1.1, 0.1, 0.1, 0.1, 0.1],\n",
    "       [0.1, 0.1, 1.1, 0.1, 0.1, 0.1],\n",
    "       [0.1, 0.1, 0.1, 1.1, 0.1, 0.1],\n",
    "       [0.1, 0.1, 0.1, 0.1, 1.1, 0.1],\n",
    "       [0.1, 0.1, 0.1, 0.1, 0.1, 1.1]])\n",
    "    sigma_u = np.array([[1.0,0.1],[0.1,1.0]])\n",
    "    \n",
    "    sigma_v = np.array([[10.0,0.0],[0.0,10.0]])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('testX.pkl','rb') as f:\n",
    "    t = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n",
      "(6, 2)\n",
      "(6, 6)\n"
     ]
    }
   ],
   "source": [
    "#tst =get_MT(t[0],sigma_theta,sigma_u,sigma_v,t,create_H())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_MS = [get_MT(x,sigma_theta,sigma_u,sigma_v,t,create_H()) for x in t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.732314267439828,\n",
       "  0.14444349891916283,\n",
       "  2.56054612626855,\n",
       "  0.17389510049973902,\n",
       "  2.6039756226612463,\n",
       "  0.18529547772734398],\n",
       " [1.1941628881993014,\n",
       "  0.18051304478717292,\n",
       "  2.72936871234552,\n",
       "  0.1688347436496591,\n",
       "  2.730599033655952,\n",
       "  0.15886895737355886],\n",
       " [0.5700555009484644,\n",
       "  0.17210316072075782,\n",
       "  0.9647352262774653,\n",
       "  0.16901978303572002,\n",
       "  0.8959034864988837,\n",
       "  0.22915185971627552],\n",
       " [1.9802768702576679,\n",
       "  0.20908923014954256,\n",
       "  2.4238906627733257,\n",
       "  0.23097841235594305,\n",
       "  2.464008140570725,\n",
       "  0.18065021665846567],\n",
       " [1.702626542065711,\n",
       "  0.2065686277569576,\n",
       "  2.8953391261470327,\n",
       "  0.1876389552064305,\n",
       "  2.9147251083132812,\n",
       "  0.1867791823574786],\n",
       " [0.7102759215500338,\n",
       "  0.19130788901508458,\n",
       "  1.1446765790298157,\n",
       "  0.20865415243282284,\n",
       "  1.1018066248976315,\n",
       "  0.21559931618297545],\n",
       " [0.6619108577714925,\n",
       "  0.20027122883197168,\n",
       "  0.8909711531900633,\n",
       "  0.19776997034407853,\n",
       "  0.8324130069334343,\n",
       "  0.19026146380520315],\n",
       " [0.18122930847187163,\n",
       "  0.17107733050648627,\n",
       "  0.23141220538062696,\n",
       "  0.22423342412642353,\n",
       "  0.2643205174756292,\n",
       "  0.17442874982847328],\n",
       " [0.7673940761042356,\n",
       "  0.16040540465799574,\n",
       "  1.0665720843682722,\n",
       "  0.17628732563399552,\n",
       "  1.0808577864702738,\n",
       "  0.14942470111171138],\n",
       " [0.2133229336959832,\n",
       "  0.17687038519734213,\n",
       "  0.19505472901216642,\n",
       "  0.17604919690667617,\n",
       "  0.21891986235618235,\n",
       "  0.17802238286259878],\n",
       " [0.20936075677434748,\n",
       "  0.227999782840115,\n",
       "  0.2795819445518492,\n",
       "  0.22593271782524077,\n",
       "  0.21242360949326508,\n",
       "  0.19236232998216393],\n",
       " [0.20122379954496852,\n",
       "  0.15901372727995627,\n",
       "  0.20535562897569967,\n",
       "  0.1640778245298723,\n",
       "  0.21088163908002944,\n",
       "  0.18902473047803112],\n",
       " [0.2072329158264406,\n",
       "  0.1894473149845507,\n",
       "  0.168804240036592,\n",
       "  0.18672328321186163,\n",
       "  0.18883089946844145,\n",
       "  0.19038533170809177],\n",
       " [0.20348747908936088,\n",
       "  0.17797624319725136,\n",
       "  0.23746778861347784,\n",
       "  0.18039456671356893,\n",
       "  0.22405342636835215,\n",
       "  0.21538011064816392],\n",
       " [0.20740589177211025,\n",
       "  0.22810158561260468,\n",
       "  0.16049017919373731,\n",
       "  0.16085376872234375,\n",
       "  0.207775726873475,\n",
       "  0.19471253539632838],\n",
       " [0.17668119383945385,\n",
       "  0.18947750990407658,\n",
       "  0.16065297997670386,\n",
       "  0.19713222910984948,\n",
       "  0.18553085036476633,\n",
       "  0.16482998481585384],\n",
       " [0.3692202917177287,\n",
       "  0.18522534853884956,\n",
       "  0.47105795488520147,\n",
       "  0.17616194318530395,\n",
       "  0.43519686191144863,\n",
       "  0.19481629003960857],\n",
       " [0.16826602459763187,\n",
       "  0.2016058683904248,\n",
       "  0.1459925447685254,\n",
       "  0.1878549346673402,\n",
       "  0.17496756466053115,\n",
       "  0.16790685083803894],\n",
       " [0.3518544431311063,\n",
       "  0.19500168400667467,\n",
       "  0.45601944329699734,\n",
       "  0.22375766854227785,\n",
       "  0.5225082560972899,\n",
       "  0.15441303372145052],\n",
       " [0.37607891618280176,\n",
       "  0.2288856860249692,\n",
       "  0.5138313409497206,\n",
       "  0.2142652573820584,\n",
       "  0.48884108481626876,\n",
       "  0.19573357379939665],\n",
       " [1.385834637318281,\n",
       "  0.2122951183304194,\n",
       "  2.460331995417273,\n",
       "  0.20678784141788087,\n",
       "  2.478341954895663,\n",
       "  0.18401489995421783],\n",
       " [0.5289595881194217,\n",
       "  0.21447954961809873,\n",
       "  0.9452187508461366,\n",
       "  0.20739079124967097,\n",
       "  0.9527154462848034,\n",
       "  0.15946555252541633],\n",
       " [0.36844601310997194,\n",
       "  0.18591961063771817,\n",
       "  0.4939999189824288,\n",
       "  0.1788375025049451,\n",
       "  0.46915740416064877,\n",
       "  0.2203964778993872],\n",
       " [0.21725228391215615,\n",
       "  0.14959933825877686,\n",
       "  0.1998343589678698,\n",
       "  0.16115120210128084,\n",
       "  0.19979346668283415,\n",
       "  0.15001525685728145],\n",
       " [0.16585911055180239,\n",
       "  0.23020810150550056,\n",
       "  0.18392339161004756,\n",
       "  0.19848121859334875,\n",
       "  0.2386331274586984,\n",
       "  0.2145459642885681],\n",
       " [0.17748667083119363,\n",
       "  0.17918844161211966,\n",
       "  0.19723673610244016,\n",
       "  0.18966230038878407,\n",
       "  0.16705765767630462,\n",
       "  0.16392232150588604],\n",
       " [0.21237555744253883,\n",
       "  0.20869877373933102,\n",
       "  0.2115575353425534,\n",
       "  0.2194792632962559,\n",
       "  0.21832236035386712,\n",
       "  0.1882288418296052],\n",
       " [0.35116224349252856,\n",
       "  0.1732414921980763,\n",
       "  0.5044065165941207,\n",
       "  0.1761241181112451,\n",
       "  0.5145933331213733,\n",
       "  0.18634865563032957],\n",
       " [0.13449683946335914,\n",
       "  0.11168137463961529,\n",
       "  0.1754019163333257,\n",
       "  0.16965745675208194,\n",
       "  0.18812791610925603,\n",
       "  0.15513985881406028],\n",
       " [0.23935004308929592,\n",
       "  0.20343411743883016,\n",
       "  0.3831810459666373,\n",
       "  0.2134995398986401,\n",
       "  0.3241333859821874,\n",
       "  0.20920180780839118],\n",
       " [0.18292801175466245,\n",
       "  0.22980674544633906,\n",
       "  0.20124967444990946,\n",
       "  0.21148489009707946,\n",
       "  0.18468714108167317,\n",
       "  0.19063620514756646],\n",
       " [0.2001962524882631,\n",
       "  0.16079153057263848,\n",
       "  0.1692356121974916,\n",
       "  0.19790432333566862,\n",
       "  0.22411788111983008,\n",
       "  0.1969067290831711],\n",
       " [0.21282678736436517,\n",
       "  0.1741140283163837,\n",
       "  0.16397720577829025,\n",
       "  0.19668303834401826,\n",
       "  0.17378702557665257,\n",
       "  0.16612572324982092],\n",
       " [0.19706470129136625,\n",
       "  0.20309392407488147,\n",
       "  0.19759250957520616,\n",
       "  0.15392562136450635,\n",
       "  0.18183006727458634,\n",
       "  0.17729043603621955],\n",
       " [0.3007420018440925,\n",
       "  0.1716290366151037,\n",
       "  0.45094374148932265,\n",
       "  0.1681092051774493,\n",
       "  0.4665645144932001,\n",
       "  0.1737392554898338],\n",
       " [0.17300913176943752,\n",
       "  0.2209406226601478,\n",
       "  0.19893375659691845,\n",
       "  0.1866837387012004,\n",
       "  0.21728259167306552,\n",
       "  0.13992114034120162],\n",
       " [0.20651743945098391,\n",
       "  0.21424509548139925,\n",
       "  0.21641586062394216,\n",
       "  0.23890089417856128,\n",
       "  0.1970883979984774,\n",
       "  0.19325894782056124],\n",
       " [0.17737007749466938,\n",
       "  0.1755424425610736,\n",
       "  0.17925518898025541,\n",
       "  0.16952467007038166,\n",
       "  0.1596333430211972,\n",
       "  0.18707637331818067],\n",
       " [0.16714942918229575,\n",
       "  0.17038684822996394,\n",
       "  0.21374682763565406,\n",
       "  0.20488791299959427,\n",
       "  0.18688035375544448,\n",
       "  0.1708339009643848],\n",
       " [0.19281749542038026,\n",
       "  0.192730249799827,\n",
       "  0.15685805953534918,\n",
       "  0.16406214274317502,\n",
       "  0.15158145149838903,\n",
       "  0.1232277669623933],\n",
       " [0.18414517960358737,\n",
       "  0.1901564048351694,\n",
       "  0.1710115789982798,\n",
       "  0.1715323396873567,\n",
       "  0.21717983034902882,\n",
       "  0.1979800677689058],\n",
       " [0.1859030362419921,\n",
       "  0.20071928043870202,\n",
       "  0.21608171874297144,\n",
       "  0.21565046851041783,\n",
       "  0.21954446367642527,\n",
       "  0.19954603917189817],\n",
       " [0.31071256559425975,\n",
       "  0.18701984761965634,\n",
       "  0.40120910107546065,\n",
       "  0.23594292903185804,\n",
       "  0.37432200293960755,\n",
       "  0.17593242456618377],\n",
       " [0.19298371141450257,\n",
       "  0.2012599752745778,\n",
       "  0.2038174649664133,\n",
       "  0.20480372344489897,\n",
       "  0.16091249036009247,\n",
       "  0.15835387092297545],\n",
       " [0.24307268302254081,\n",
       "  0.23803765719240885,\n",
       "  0.2115929768545702,\n",
       "  0.2446567370190112,\n",
       "  0.21273037994761101,\n",
       "  0.21025483641558057],\n",
       " [0.21076333076572,\n",
       "  0.19021111666049176,\n",
       "  0.1973417295916732,\n",
       "  0.20494925282142987,\n",
       "  0.1944045344285435,\n",
       "  0.17917983601152768],\n",
       " [0.35251535620144914,\n",
       "  0.1733057583385132,\n",
       "  0.43677473708765074,\n",
       "  0.16589196620732355,\n",
       "  0.45447549926476966,\n",
       "  0.16006030223852516],\n",
       " [0.1905340170299216,\n",
       "  0.1843159009244621,\n",
       "  0.19991241327772738,\n",
       "  0.17167183963430319,\n",
       "  0.1751084681095243,\n",
       "  0.15852983727057945],\n",
       " [0.1943276528310216,\n",
       "  0.1846995743646838,\n",
       "  0.17586997438033886,\n",
       "  0.18224480761030237,\n",
       "  0.17775433669652704,\n",
       "  0.18851430036207617],\n",
       " [0.13361835396214417,\n",
       "  0.16323973112724488,\n",
       "  0.17532276717506862,\n",
       "  0.15844427855046278,\n",
       "  0.16672540016326623,\n",
       "  0.20726578054956776],\n",
       " [0.1843930706643513,\n",
       "  0.20825295206367495,\n",
       "  0.2147353993815429,\n",
       "  0.20001664160338345,\n",
       "  0.2359318110114276,\n",
       "  0.1914399392676836],\n",
       " [0.305303331090271,\n",
       "  0.18047622561258694,\n",
       "  0.36211651175678694,\n",
       "  0.1911607618212065,\n",
       "  0.39195357038002343,\n",
       "  0.20997402007508995],\n",
       " [0.23684254090210113,\n",
       "  0.25400080647306145,\n",
       "  0.2002692202448442,\n",
       "  0.2003428720104695,\n",
       "  0.1784206911053336,\n",
       "  0.20057362460235767],\n",
       " [0.17797138815095545,\n",
       "  0.18277879929835242,\n",
       "  0.19413068657928106,\n",
       "  0.1515834588950011,\n",
       "  0.15540686548000754,\n",
       "  0.17363321203271628],\n",
       " [0.3101461889076523,\n",
       "  0.16382783106738874,\n",
       "  0.44198911156974946,\n",
       "  0.20852408073905687,\n",
       "  0.4570177087252567,\n",
       "  0.21070838979733],\n",
       " [0.3393565483690345,\n",
       "  0.2129471008253498,\n",
       "  0.44744845947599765,\n",
       "  0.177649810217757,\n",
       "  0.41340248654366396,\n",
       "  0.17770506612487158],\n",
       " [0.3388122995014147,\n",
       "  0.19171594579387705,\n",
       "  0.46010640897072813,\n",
       "  0.17006505510682168,\n",
       "  0.4355114611138199,\n",
       "  0.1659651044951088],\n",
       " [0.37352376789724845,\n",
       "  0.19210283785408186,\n",
       "  0.4476778867991128,\n",
       "  0.16343590463172697,\n",
       "  0.4244563976582638,\n",
       "  0.206263356722419],\n",
       " [0.16847142685550462,\n",
       "  0.19869107922233753,\n",
       "  0.19731808254261207,\n",
       "  0.2030505587006527,\n",
       "  0.1889714556565782,\n",
       "  0.18297079804516578],\n",
       " [0.1824300972490575,\n",
       "  0.17826734668589828,\n",
       "  0.1371248343470371,\n",
       "  0.1605968755023914,\n",
       "  0.2035459346115697,\n",
       "  0.15814395603949388],\n",
       " [0.308956569712573,\n",
       "  0.1928730782222577,\n",
       "  0.4581860420001587,\n",
       "  0.14307483257929404,\n",
       "  0.46734589477547483,\n",
       "  0.1670171835825766],\n",
       " [0.16154744616602396,\n",
       "  0.15633045978522084,\n",
       "  0.17097249822636892,\n",
       "  0.20217471982736918,\n",
       "  0.16455035234304963,\n",
       "  0.17630571041925033],\n",
       " [0.17300594040094405,\n",
       "  0.18503542368793885,\n",
       "  0.19206320609266228,\n",
       "  0.15407878379110998,\n",
       "  0.19614608872089592,\n",
       "  0.19931086348048244],\n",
       " [0.35998621140374865,\n",
       "  0.15625066697087764,\n",
       "  0.47840372481773225,\n",
       "  0.1887531586949679,\n",
       "  0.4637903114558872,\n",
       "  0.18171959852493616],\n",
       " [0.2178426039422062,\n",
       "  0.2167409713024809,\n",
       "  0.1956460848550138,\n",
       "  0.18488376599197942,\n",
       "  0.20101861988311115,\n",
       "  0.22285465403139942],\n",
       " [0.1805887798761513,\n",
       "  0.20964843954925713,\n",
       "  0.23388964019546477,\n",
       "  0.20325769667823707,\n",
       "  0.17523822107879533,\n",
       "  0.16301356213132964],\n",
       " [0.2510415951020976,\n",
       "  0.2402014694035316,\n",
       "  0.17918135073463762,\n",
       "  0.21463976807258686,\n",
       "  0.21816571218498296,\n",
       "  0.19465819931827844],\n",
       " [0.3198361953183147,\n",
       "  0.24412848205376378,\n",
       "  0.48456391986594244,\n",
       "  0.2195362952602478,\n",
       "  0.4561693889381425,\n",
       "  0.231715172783061],\n",
       " [0.39173340092339376,\n",
       "  0.1985017281247897,\n",
       "  0.47375217681848203,\n",
       "  0.1596947529564599,\n",
       "  0.49599421581477354,\n",
       "  0.1859676851783888],\n",
       " [0.13017627777366475,\n",
       "  0.18145981759290414,\n",
       "  0.189449151454792,\n",
       "  0.23784402344404906,\n",
       "  0.17447988454273272,\n",
       "  0.1837332433353644],\n",
       " [0.31979613825240766,\n",
       "  0.18124477420802895,\n",
       "  0.40642372558540174,\n",
       "  0.21936819909382227,\n",
       "  0.42873041632027237,\n",
       "  0.22344195909439665],\n",
       " [0.23400100094710974,\n",
       "  0.19037716305383698,\n",
       "  0.23036931293145577,\n",
       "  0.21570726961007475,\n",
       "  0.1922668449208018,\n",
       "  0.20286270956330324],\n",
       " [0.13798707727567605,\n",
       "  0.17309174451133208,\n",
       "  0.17551212872833025,\n",
       "  0.18928580329117523,\n",
       "  0.19398385118421554,\n",
       "  0.19609095430782633],\n",
       " [0.20638729534816494,\n",
       "  0.21122755386065356,\n",
       "  0.20050375703306805,\n",
       "  0.1813182948186567,\n",
       "  0.19606395499213136,\n",
       "  0.23208999075248374],\n",
       " [0.18818387771986997,\n",
       "  0.15238939553808198,\n",
       "  0.18484743213609595,\n",
       "  0.19426575060513934,\n",
       "  0.1498881754921136,\n",
       "  0.22739827723895523],\n",
       " [0.23477273699462728,\n",
       "  0.20274086995782495,\n",
       "  0.20768353464740882,\n",
       "  0.19774005664999017,\n",
       "  0.17201900501964937,\n",
       "  0.19731204069295216],\n",
       " [0.3115162613542793,\n",
       "  0.1948590071980118,\n",
       "  0.46091590543921274,\n",
       "  0.17201864876302905,\n",
       "  0.45618807868953803,\n",
       "  0.18933356899729684],\n",
       " [0.19942248372202584,\n",
       "  0.1914028452412695,\n",
       "  0.21048517231511862,\n",
       "  0.18784112368857006,\n",
       "  0.19885872526528267,\n",
       "  0.2274065371341096],\n",
       " [0.19113131188425309,\n",
       "  0.1557096735242901,\n",
       "  0.2046000541160023,\n",
       "  0.16142651354697216,\n",
       "  0.19465614231319592,\n",
       "  0.2140614145453752],\n",
       " [0.32840233057034496,\n",
       "  0.21392211069595576,\n",
       "  0.5215535346607517,\n",
       "  0.1635012443263934,\n",
       "  0.5030177349922359,\n",
       "  0.18581181711622247],\n",
       " [0.24412217551648066,\n",
       "  0.172248933508385,\n",
       "  0.19979651091587983,\n",
       "  0.200302347462616,\n",
       "  0.19495079801523943,\n",
       "  0.23087735832546774],\n",
       " [0.14166141544455924,\n",
       "  0.14668353575432017,\n",
       "  0.16815263800812832,\n",
       "  0.19952832012303537,\n",
       "  0.1318353599581132,\n",
       "  0.13873875966917065],\n",
       " [0.3922227186282903,\n",
       "  0.20794040038383393,\n",
       "  0.43040328303459285,\n",
       "  0.1965657788313193,\n",
       "  0.4300468183297768,\n",
       "  0.19374402824015097],\n",
       " [0.18987148456299313,\n",
       "  0.22075073256915723,\n",
       "  0.1991519099358912,\n",
       "  0.1822012675870602,\n",
       "  0.1652932786851588,\n",
       "  0.20898978505218485],\n",
       " [0.23223614594334263,\n",
       "  0.18822769709098533,\n",
       "  0.17350476033486828,\n",
       "  0.17688674369486326,\n",
       "  0.18833122566494823,\n",
       "  0.19903143298939005],\n",
       " [0.2269881544839449,\n",
       "  0.1683296474447274,\n",
       "  0.18886340373571484,\n",
       "  0.2295136511470909,\n",
       "  0.18916574103661457,\n",
       "  0.20784962736090706],\n",
       " [0.1946645360895778,\n",
       "  0.1780540555898891,\n",
       "  0.17914836439535256,\n",
       "  0.20572077672593844,\n",
       "  0.17497303130475297,\n",
       "  0.2183428849530217],\n",
       " [0.17598108416731062,\n",
       "  0.19180777025268528,\n",
       "  0.20151751018695818,\n",
       "  0.20680260774524148,\n",
       "  0.18715645267693218,\n",
       "  0.18716905824143737],\n",
       " [0.4038371602098998,\n",
       "  0.1784262375998614,\n",
       "  0.40322718085603804,\n",
       "  0.22507581300749152,\n",
       "  0.4017524325267402,\n",
       "  0.15470245425149198],\n",
       " [0.23170185771609314,\n",
       "  0.19518216177178396,\n",
       "  0.18129469582990468,\n",
       "  0.17438420748936592,\n",
       "  0.1657510429827055,\n",
       "  0.16707040757536598],\n",
       " [0.25413048792401216,\n",
       "  0.18331396359553387,\n",
       "  0.2227540322298499,\n",
       "  0.1977853706429518,\n",
       "  0.17016755701342007,\n",
       "  0.1955156157205195],\n",
       " [0.19587968349183404,\n",
       "  0.20312147628053706,\n",
       "  0.21789788332965257,\n",
       "  0.17190872816720115,\n",
       "  0.19935190648506598,\n",
       "  0.22812628238468097],\n",
       " [0.20209890967870445,\n",
       "  0.17490545626272538,\n",
       "  0.17273690318359183,\n",
       "  0.15080382276752138,\n",
       "  0.1921302125909517,\n",
       "  0.19884983315644686],\n",
       " [0.17686366666049722,\n",
       "  0.17955011219914024,\n",
       "  0.17825393661656186,\n",
       "  0.1995675563808433,\n",
       "  0.16385754194447102,\n",
       "  0.19457694943039336],\n",
       " [0.18019574354667217,\n",
       "  0.2158816863560223,\n",
       "  0.19658354668013825,\n",
       "  0.2226919132714391,\n",
       "  0.2074480684723014,\n",
       "  0.1978527527435896],\n",
       " [0.20657328673040654,\n",
       "  0.1739083006880759,\n",
       "  0.21130196769451645,\n",
       "  0.1742385348409298,\n",
       "  0.2170069338922476,\n",
       "  0.15016951402011758],\n",
       " [0.13613551389209103,\n",
       "  0.18220302915828152,\n",
       "  0.15301536859259546,\n",
       "  0.18288238021802933,\n",
       "  0.18169308612948093,\n",
       "  0.16134306804324286],\n",
       " [0.20641706880049682,\n",
       "  0.1985244319310344,\n",
       "  0.17471917678373494,\n",
       "  0.21699250871455197,\n",
       "  0.22245180604782927,\n",
       "  0.19384114330602586],\n",
       " [0.19910718430800559,\n",
       "  0.17872798565023387,\n",
       "  0.16365699182305118,\n",
       "  0.17512068584191115,\n",
       "  0.18263159857944203,\n",
       "  0.17526792296058574],\n",
       " [0.2397059101200039,\n",
       "  0.1272105167577739,\n",
       "  0.21985187737343376,\n",
       "  0.23009899449161203,\n",
       "  0.21508235306191967,\n",
       "  0.20905035986052178]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_MS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'norm_9/Squeeze:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one = tf.constant([0,0])\n",
    "#two = tf.constant([1,1])\n",
    "inp= tf.constant([[1.0, 2, 3], [4, 5, 6.0], [7.0, 8, 9]])\n",
    "tf.norm([inp,inp],ord=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X,columns=['f_1','f_2','f_3','f_4','f_5','f_6','g_1','g_2','user_id','user_day_id'])\n",
    "path = 'X_data.feather'\n",
    "feather.write_dataframe(df, path)\n",
    "df_rewards = pd.DataFrame(y,columns=['reward'])\n",
    "path = 'y_data.feather'\n",
    "feather.write_dataframe(df_rewards, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = 'adjusted_R.feather'\n",
    "#feather.write_dataframe(df, path)\n",
    "df_rewardsa = pd.DataFrame(r_adjusted,columns=['reward_centered'])\n",
    "path = 'adjusted_R.feather'\n",
    "feather.write_dataframe(df_rewardsa , path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_MS[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpy2.rinterface.NULL"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rpy2.robjects import numpy2ri\n",
    "import rpy2.robjects as robjects\n",
    "write_csv = robjects.r('write.csv')\n",
    "write_csv(all_MS,'filename.csv')\n",
    "#r(\"save(foo, file='here.gzip', compress=TRUE)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('temp_M.pkl','wb') as f:\n",
    "    pickle.dump(all_MS,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rewardsa = pd.DataFrame(trm,columns=['u_{}'.format(i) for i in range(100)])\n",
    "path = 'covar_from_kernel_on_train.feather'\n",
    "feather.write_dataframe(df_rewardsa , path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rewardsa = pd.DataFrame(sigma_theta,columns=['i_{}'.format(i) for i in range(6)])\n",
    "path = 'sigma_theta.feather'\n",
    "feather.write_dataframe(df_rewardsa , path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rewardsa = pd.DataFrame(sigma_u,columns=['i_{}'.format(i) for i in range(2)])\n",
    "path = 'sigma_u.feather'\n",
    "feather.write_dataframe(df_rewardsa , path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rewardsa = pd.DataFrame(sigma_v,columns=['i_{}'.format(i) for i in range(2)])\n",
    "path = 'sigma_v.feather'\n",
    "feather.write_dataframe(df_rewardsa , path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 2, 2, 2, 3, 3, 3], [1, 1, 2, 2, 2, 3, 3, 3]]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def rbf_custom( X, X2=None):\n",
    "        #print(X)\n",
    "        #print(X2)\n",
    "        if X2 is None:\n",
    "             X2=X\n",
    "        return tf.exp(tf.divide(tf.square(-tf.subtract(X,X2)),tf.constant(1.0,dtype=tf.float64)))\n",
    "        return tf.constant(1.0,dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    }
   ],
   "source": [
    "tx = tf.constant(X)\n",
    "day_two = gather_cols(tx, [6], name=None)\n",
    "z= rbf_custom(day_two,day_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Exp_756:0' shape=(100, 1) dtype=float64>"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_sigmas(sigma_v,g_one,g_two,day_one,day_two):\n",
    "    #sigmax = [[] for i in range(100)]\n",
    "    #tf.placeholder(tf.float64, shape=(100, 2,2))\n",
    "    \n",
    "            \n",
    "        #print('eff')\n",
    "        #print(effects.shape)\n",
    "        #user_term = tf.constant(np.array([[0.0,0.0],[0.0,0.0]]))           \n",
    "        \n",
    "\n",
    "\n",
    "        #print('eff')\n",
    "        #print(effects.shape)\n",
    "        #effects = tf.tensordot(effects,tf.transpose(g_two),axes = [[1],[0]])\n",
    "    \n",
    "    get_g = g_one\n",
    "    get_g_two = g_two\n",
    "    to_return = [[] for i in range(get_g.get_shape()[0])]\n",
    "    for i in range(get_g.get_shape()[0]):\n",
    "        temp = [[] for i in range(get_g_two.get_shape()[0])]\n",
    "        for j in range( get_g_two.get_shape()[0]):\n",
    "            rho = rbf_custom(day_one[i], X2=day_two[j])\n",
    "            #print(sess.run(rho))\n",
    "            val = sess.run(rho)[0]\n",
    "        #tf.scalar_mul(val,sigma_v)\n",
    "            #print(val)\n",
    "            this_sigma = tf.scalar_mul(val,sigma_v)\n",
    "            #print(this_sigma)\n",
    "            effects = tf.tensordot(get_g[i],this_sigma,axes=[[0],[1]])\n",
    "            effects = tf.tensordot(effects,get_g_two[j],axes = [[0],[0]])\n",
    "            temp[j]=effects\n",
    "        to_return[i]=temp\n",
    "        \n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sess.run(z[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    }
   ],
   "source": [
    "        day_one = gather_cols(X, [6], name=None)\n",
    "        f_one = gather_cols(X, [0,1,2], name=None)\n",
    "        g_one = gather_cols(X, [3,4], name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_100004:0' shape=() dtype=float64>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_custom(day_one[0], X2=day_two[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_two=g_one\n",
    "day_two=day_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = tf.stack([day_one,day_two],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-5af5d324f559>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0melems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0malternate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrbf_custom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'tensor'"
     ]
    }
   ],
   "source": [
    "elems = ts\n",
    "\n",
    "alternate = tf.map_fn(lambda x: rbf_custom(x[0], X2=x[1]), elems, dtype=(tf.tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_theta =tf.constant(np.array([[100.0,10.0,10.0],[10.0,100.0,10.0],\\\n",
    "                                    [10.0,10.0,100.0]]))\n",
    "sigma_v =  tf.constant(np.array([[100.0,0.0],[0.0,100.0]]))\n",
    "sigma_u =  tf.constant(np.array([[100.0,10.0],[10.0,100.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho\n",
      "1.0\n",
      "(3,)\n",
      "Tensor(\"strided_slice_206:0\", shape=(3,), dtype=float64)\n",
      "baselines\n",
      "(3,)\n",
      "baselines\n",
      "()\n",
      "107826.87763336947\n",
      "eff\n",
      "(2,)\n",
      "eff\n",
      "()\n",
      "res\n",
      "()\n",
      "169293.14642401805\n"
     ]
    }
   ],
   "source": [
    "user_id_one = X_one[-2]\n",
    "day_one = X_one[-1]\n",
    "f_one = X_one[0:3]\n",
    "g_one = X_one[3:5]\n",
    "\n",
    "user_id_two = X_two[-2]\n",
    "day_two = X_two[-1]\n",
    "f_two = X_two[0:3]\n",
    "g_two = X_two[3:5]\n",
    "        \n",
    "        \n",
    "rho_term = rbf_custom(day_one,X2=day_two).eval(session=sess) \n",
    "#print(sess.run(rho_term))\n",
    "print('rho')\n",
    "#print(tf.shape(f_one))\n",
    "print(rho_term)\n",
    "print(f_one.shape)\n",
    "print(f_one)\n",
    "#print(rho_term.get_shape()[1])\n",
    "            #rho_term = tf.constant(np.array([1.0]))\n",
    "       \n",
    "baselines = tf.tensordot(tf.transpose(f_one),sigma_theta,axes=[[0],[0]])\n",
    "print('baselines')\n",
    "print(baselines.get_shape())\n",
    "baselines = tf.tensordot(tf.transpose(baselines),f_two,axes=[[0],[0]])\n",
    "            #print('look at shape')\n",
    "            #print(baselines)\n",
    "print('baselines')\n",
    "print(baselines.get_shape())\n",
    "print(baselines.eval(session=sess))\n",
    "#if user_id_one==user_id_two:\n",
    "#    user_term = self.sigma_u\n",
    "#else:\n",
    "#print('user')\n",
    "#print('user_term')\n",
    "\n",
    "            #print(self.sigma_v.shape)\n",
    "            #print(rho_term.shape)\n",
    "effect_term = tf.scalar_mul(rho_term,sigma_v)\n",
    "#print('effect term')\n",
    "#print(effect_term.shape)\n",
    "#print('user term')\n",
    "#print(user_term.shape)\n",
    "user_term = tf.constant(np.array([[0.0,0.0],[0.0,0.0]]))           \n",
    "effect_term = tf.add(user_term,effect_term)\n",
    "#print('eff')\n",
    "#print(effect_term.shape)\n",
    "#print('g')\n",
    "#print(g_one.shape)\n",
    "effects = tf.tensordot(tf.transpose(g_one),effect_term,axes=[[0],[1]])\n",
    "print('eff')\n",
    "print(effects.shape)\n",
    "effects = tf.tensordot(tf.transpose(effects),g_two,axes = [[0],[0]])\n",
    "print('eff')\n",
    "print(effects.shape)\n",
    "result = tf.add(baselines,effects)\n",
    "print('res')\n",
    "print(result.shape)\n",
    "print(result.eval(session=sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack([np.random.randn(10,2) + [2,2],\n",
    "               np.random.randn(10,2) + [-2,2],\n",
    "               np.random.randn(10,2) + [2,-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 2)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #.eval(session=sess) \n",
    "            #print(sess.run(rho_term))\n",
    "            print('rho')\n",
    "            #print(tf.shape(f_one))\n",
    "            print(rho_term)\n",
    "            print(f_one.shape)\n",
    "            print(f_one)\n",
    "            #print(rho_term.get_shape()[1])\n",
    "            #rho_term = tf.constant(np.array([1.0]))\n",
    "       \n",
    "            baselines = tf.tensordot(tf.transpose(f_one),self.sigma_theta,axes=[[0],[0]])\n",
    "            print('baselines')\n",
    "            print(baselines.get_shape())\n",
    "            baselines = tf.tensordot(tf.transpose(baselines),f_two,axes=[[0],[0]])\n",
    "            #print('look at shape')\n",
    "            #print(baselines)\n",
    "            print('baselines')\n",
    "            print(baselines.get_shape())\n",
    "           \n",
    "            #if user_id_one==user_id_two:\n",
    "            #    user_term = self.sigma_u\n",
    "            #else:\n",
    "            #print('user')\n",
    "            #print('user_term')\n",
    "\n",
    "            #print(self.sigma_v.shape)\n",
    "            #print(rho_term.shape)\n",
    "            effect_term = tf.tensordot(rho_term,self.sigma_v,axes=[[0],[0]])\n",
    "                #print('effect term')\n",
    "            #print(effect_term.shape)\n",
    "            #print('user term')\n",
    "            #print(user_term.shape)\n",
    "            user_term = tf.constant(np.array([[0.0,0.0],[0.0,0.0]]))           \n",
    "            effect_term = tf.add(user_term,effect_term)\n",
    "            #print('eff')\n",
    "            #print(effect_term.shape)\n",
    "            #print('g')\n",
    "            #print(g_one.shape)\n",
    "            effects = tf.tensordot(tf.transpose(g_one),effect_term,axes=[[0],[1]])\n",
    "            print('eff')\n",
    "            print(effects.shape)\n",
    "            effects = tf.tensordot(tf.transpose(effects),g_two,axes = [[0],[0]])\n",
    "            print('eff')\n",
    "            print(effects.shape)\n",
    "            result = tf.add(baselines,effects)\n",
    "            print('res')\n",
    "            print(result.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('temp_M.pkl','rb') as f:\n",
    "    M=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.array(M[0]).shape\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rewardsa = pd.DataFrame(M[0],columns=['p_1','p_2','p_3','p_4','p_5','p_6'])\n",
    "path = 'M0.feather'\n",
    "feather.write_dataframe(df_rewardsa , path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.732314267439828,\n",
       "  0.14444349891916283,\n",
       "  2.56054612626855,\n",
       "  0.17389510049973902,\n",
       "  2.6039756226612463,\n",
       "  0.18529547772734398],\n",
       " [1.5735088680249458,\n",
       "  0.14444349891916283,\n",
       "  2.3292300381569624,\n",
       "  0.17389510049973902,\n",
       "  2.3726595345496593,\n",
       "  0.18529547772734398],\n",
       " [0.707224096966215,\n",
       "  0.14444349891916283,\n",
       "  0.9536619664315121,\n",
       "  0.17389510049973902,\n",
       "  0.9970914628242088,\n",
       "  0.18529547772734398],\n",
       " [1.5735088680249458,\n",
       "  0.14444349891916283,\n",
       "  2.3292300381569624,\n",
       "  0.17389510049973902,\n",
       "  2.3726595345496593,\n",
       "  0.18529547772734398],\n",
       " [1.5735088680249458,\n",
       "  0.14444349891916283,\n",
       "  2.3292300381569624,\n",
       "  0.17389510049973902,\n",
       "  2.3726595345496593,\n",
       "  0.18529547772734398],\n",
       " [0.707224096966215,\n",
       "  0.14444349891916283,\n",
       "  0.9536619664315121,\n",
       "  0.17389510049973902,\n",
       "  0.9970914628242088,\n",
       "  0.18529547772734398],\n",
       " [0.707224096966215,\n",
       "  0.14444349891916283,\n",
       "  0.9536619664315121,\n",
       "  0.17389510049973902,\n",
       "  0.9970914628242088,\n",
       "  0.18529547772734398],\n",
       " [0.22816706551626026,\n",
       "  0.14444349891916283,\n",
       "  0.19297035668202406,\n",
       "  0.17389510049973902,\n",
       "  0.2363998530747207,\n",
       "  0.18529547772734398],\n",
       " [0.8660294963810972,\n",
       "  0.14444349891916283,\n",
       "  1.1849780545430992,\n",
       "  0.17389510049973902,\n",
       "  1.2284075509357961,\n",
       "  0.18529547772734398],\n",
       " [0.22816706551626026,\n",
       "  0.14444349891916283,\n",
       "  0.19297035668202406,\n",
       "  0.17389510049973902,\n",
       "  0.2363998530747207,\n",
       "  0.18529547772734398],\n",
       " [0.22816706551626026,\n",
       "  0.14444349891916283,\n",
       "  0.19297035668202406,\n",
       "  0.17389510049973902,\n",
       "  0.2363998530747207,\n",
       "  0.18529547772734398],\n",
       " [0.20323566471378116,\n",
       "  0.14444349891916283,\n",
       "  0.153381944103367,\n",
       "  0.17389510049973902,\n",
       "  0.1968114404960636,\n",
       "  0.18529547772734398],\n",
       " [0.20306669291737336,\n",
       "  0.14444349891916283,\n",
       "  0.1531136348638122,\n",
       "  0.17389510049973902,\n",
       "  0.19654313125650882,\n",
       "  0.18529547772734398],\n",
       " [0.203066538713439,\n",
       "  0.14444349891916283,\n",
       "  0.15311339000436677,\n",
       "  0.17389510049973902,\n",
       "  0.19654288639706338,\n",
       "  0.18529547772734398],\n",
       " [0.2030665386944067,\n",
       "  0.14444349891916283,\n",
       "  0.15311338997414548,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668421,\n",
       "  0.18529547772734398],\n",
       " [0.20323566471378116,\n",
       "  0.14444349891916283,\n",
       "  0.153381944103367,\n",
       "  0.17389510049973902,\n",
       "  0.1968114404960636,\n",
       "  0.18529547772734398],\n",
       " [0.38697246493114246,\n",
       "  0.14444349891916283,\n",
       "  0.4242864447936113,\n",
       "  0.17389510049973902,\n",
       "  0.4677159411863079,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.3620410641286633,\n",
       "  0.14444349891916283,\n",
       "  0.38469803221495413,\n",
       "  0.17389510049973902,\n",
       "  0.42812752860765074,\n",
       "  0.18529547772734398],\n",
       " [0.3618720923322556,\n",
       "  0.14444349891916283,\n",
       "  0.3844297229753994,\n",
       "  0.17389510049973902,\n",
       "  0.427859219368096,\n",
       "  0.18529547772734398],\n",
       " [1.5735088680249458,\n",
       "  0.14444349891916283,\n",
       "  2.3292300381569624,\n",
       "  0.17389510049973902,\n",
       "  2.3726595345496593,\n",
       "  0.18529547772734398],\n",
       " [0.707224096966215,\n",
       "  0.14444349891916283,\n",
       "  0.9536619664315121,\n",
       "  0.17389510049973902,\n",
       "  0.9970914628242088,\n",
       "  0.18529547772734398],\n",
       " [0.36187193812832125,\n",
       "  0.14444349891916283,\n",
       "  0.38442947811595396,\n",
       "  0.17389510049973902,\n",
       "  0.42785897450865057,\n",
       "  0.18529547772734398],\n",
       " [0.22816706551626026,\n",
       "  0.14444349891916283,\n",
       "  0.19297035668202406,\n",
       "  0.17389510049973902,\n",
       "  0.2363998530747207,\n",
       "  0.18529547772734398],\n",
       " [0.20306669291737336,\n",
       "  0.14444349891916283,\n",
       "  0.1531136348638122,\n",
       "  0.17389510049973902,\n",
       "  0.19654313125650882,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20323566471378116,\n",
       "  0.14444349891916283,\n",
       "  0.153381944103367,\n",
       "  0.17389510049973902,\n",
       "  0.1968114404960636,\n",
       "  0.18529547772734398],\n",
       " [0.3618719381092889,\n",
       "  0.14444349891916283,\n",
       "  0.3844294780857327,\n",
       "  0.17389510049973902,\n",
       "  0.4278589744784293,\n",
       "  0.18529547772734398],\n",
       " [0.20306669291737336,\n",
       "  0.14444349891916283,\n",
       "  0.1531136348638122,\n",
       "  0.17389510049973902,\n",
       "  0.19654313125650882,\n",
       "  0.18529547772734398],\n",
       " [0.3618719381092886,\n",
       "  0.14444349891916283,\n",
       "  0.3844294780857322,\n",
       "  0.17389510049973902,\n",
       "  0.4278589744784288,\n",
       "  0.18529547772734398],\n",
       " [0.203066538713439,\n",
       "  0.14444349891916283,\n",
       "  0.15311339000436677,\n",
       "  0.17389510049973902,\n",
       "  0.19654288639706338,\n",
       "  0.18529547772734398],\n",
       " [0.20323566471378116,\n",
       "  0.14444349891916283,\n",
       "  0.153381944103367,\n",
       "  0.17389510049973902,\n",
       "  0.1968114404960636,\n",
       "  0.18529547772734398],\n",
       " [0.2030665386944067,\n",
       "  0.14444349891916283,\n",
       "  0.15311338997414548,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668421,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.3618719381092886,\n",
       "  0.14444349891916283,\n",
       "  0.3844294780857322,\n",
       "  0.17389510049973902,\n",
       "  0.4278589744784288,\n",
       "  0.18529547772734398],\n",
       " [0.203066538713439,\n",
       "  0.14444349891916283,\n",
       "  0.15311339000436677,\n",
       "  0.17389510049973902,\n",
       "  0.19654288639706338,\n",
       "  0.18529547772734398],\n",
       " [0.2030665386944067,\n",
       "  0.14444349891916283,\n",
       "  0.15311338997414548,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668421,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306669291737336,\n",
       "  0.14444349891916283,\n",
       "  0.1531136348638122,\n",
       "  0.17389510049973902,\n",
       "  0.19654313125650882,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.3618719381092886,\n",
       "  0.14444349891916283,\n",
       "  0.3844294780857322,\n",
       "  0.17389510049973902,\n",
       "  0.4278589744784288,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.3618719381092886,\n",
       "  0.14444349891916283,\n",
       "  0.3844294780857322,\n",
       "  0.17389510049973902,\n",
       "  0.4278589744784288,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.3618719381092886,\n",
       "  0.14444349891916283,\n",
       "  0.3844294780857322,\n",
       "  0.17389510049973902,\n",
       "  0.4278589744784288,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.3618719381092886,\n",
       "  0.14444349891916283,\n",
       "  0.3844294780857322,\n",
       "  0.17389510049973902,\n",
       "  0.4278589744784288,\n",
       "  0.18529547772734398],\n",
       " [0.3618719381092886,\n",
       "  0.14444349891916283,\n",
       "  0.3844294780857322,\n",
       "  0.17389510049973902,\n",
       "  0.4278589744784288,\n",
       "  0.18529547772734398],\n",
       " [0.3618719381092886,\n",
       "  0.14444349891916283,\n",
       "  0.3844294780857322,\n",
       "  0.17389510049973902,\n",
       "  0.4278589744784288,\n",
       "  0.18529547772734398],\n",
       " [0.3618719381092886,\n",
       "  0.14444349891916283,\n",
       "  0.3844294780857322,\n",
       "  0.17389510049973902,\n",
       "  0.4278589744784288,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.3618719381092886,\n",
       "  0.14444349891916283,\n",
       "  0.3844294780857322,\n",
       "  0.17389510049973902,\n",
       "  0.4278589744784288,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.3618719381092886,\n",
       "  0.14444349891916283,\n",
       "  0.3844294780857322,\n",
       "  0.17389510049973902,\n",
       "  0.4278589744784288,\n",
       "  0.18529547772734398],\n",
       " [0.203066538713439,\n",
       "  0.14444349891916283,\n",
       "  0.15311339000436677,\n",
       "  0.17389510049973902,\n",
       "  0.19654288639706338,\n",
       "  0.18529547772734398],\n",
       " [0.2030665386944067,\n",
       "  0.14444349891916283,\n",
       "  0.15311338997414548,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668421,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.3618719381092886,\n",
       "  0.14444349891916283,\n",
       "  0.3844294780857322,\n",
       "  0.17389510049973902,\n",
       "  0.4278589744784288,\n",
       "  0.18529547772734398],\n",
       " [0.3618719381092886,\n",
       "  0.14444349891916283,\n",
       "  0.3844294780857322,\n",
       "  0.17389510049973902,\n",
       "  0.4278589744784288,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.3618719381092886,\n",
       "  0.14444349891916283,\n",
       "  0.3844294780857322,\n",
       "  0.17389510049973902,\n",
       "  0.4278589744784288,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.3618719381092886,\n",
       "  0.14444349891916283,\n",
       "  0.3844294780857322,\n",
       "  0.17389510049973902,\n",
       "  0.4278589744784288,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.3618719381092886,\n",
       "  0.14444349891916283,\n",
       "  0.3844294780857322,\n",
       "  0.17389510049973902,\n",
       "  0.4278589744784288,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.3618719381092886,\n",
       "  0.14444349891916283,\n",
       "  0.3844294780857322,\n",
       "  0.17389510049973902,\n",
       "  0.4278589744784288,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.3618719381092886,\n",
       "  0.14444349891916283,\n",
       "  0.3844294780857322,\n",
       "  0.17389510049973902,\n",
       "  0.4278589744784288,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398],\n",
       " [0.20306653869440638,\n",
       "  0.14444349891916283,\n",
       "  0.153113389974145,\n",
       "  0.17389510049973902,\n",
       "  0.1965428863668416,\n",
       "  0.18529547772734398]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
